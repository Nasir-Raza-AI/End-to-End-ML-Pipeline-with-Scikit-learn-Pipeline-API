{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95337e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# pip install scikit-learn pandas numpy joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af446540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7043, 21)\n",
      "\n",
      "Columns: ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
      "\n",
      "Missing values:\n",
      " customerID          0\n",
      "gender              0\n",
      "SeniorCitizen       0\n",
      "Partner             0\n",
      "Dependents          0\n",
      "tenure              0\n",
      "PhoneService        0\n",
      "MultipleLines       0\n",
      "InternetService     0\n",
      "OnlineSecurity      0\n",
      "OnlineBackup        0\n",
      "DeviceProtection    0\n",
      "TechSupport         0\n",
      "StreamingTV         0\n",
      "StreamingMovies     0\n",
      "Contract            0\n",
      "PaperlessBilling    0\n",
      "PaymentMethod       0\n",
      "MonthlyCharges      0\n",
      "TotalCharges        0\n",
      "Churn               0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      " customerID           object\n",
      "gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure                int64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "MonthlyCharges      float64\n",
      "TotalCharges         object\n",
      "Churn                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (replace with your file path)\n",
    "# Dataset can be downloaded from: https://www.kaggle.com/blastchar/telco-customer-churn\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "print(\"\\nData types:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab1bfe76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (5634, 19)\n",
      "Test set size: (1409, 19)\n",
      "Churn distribution in training: Churn\n",
      "0    0.734647\n",
      "1    0.265353\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Clean the data\n",
    "def preprocess_data(df):\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Convert TotalCharges to numeric, handling errors\n",
    "    df_clean['TotalCharges'] = pd.to_numeric(df_clean['TotalCharges'], errors='coerce')\n",
    "    \n",
    "    # Drop customerID as it's not useful for prediction\n",
    "    df_clean = df_clean.drop('customerID', axis=1)\n",
    "    \n",
    "    # Handle missing values in TotalCharges (replace with median)\n",
    "    df_clean['TotalCharges'].fillna(df_clean['TotalCharges'].median(), inplace=True)\n",
    "    \n",
    "    # Convert target variable to binary\n",
    "    df_clean['Churn'] = df_clean['Churn'].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Preprocess the data\n",
    "df_clean = preprocess_data(df)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_clean.drop('Churn', axis=1)\n",
    "y = df_clean['Churn']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "print(f\"Churn distribution in training: {y_train.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efb4aa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
      "Categorical columns: ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical and categorical columns\n",
    "numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "categorical_cols = [col for col in X.columns if col not in numerical_cols]\n",
    "\n",
    "print(\"Numerical columns:\", numerical_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce23343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Handle any remaining missing values\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93dbceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Pipeline\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "# Random Forest Pipeline\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b93daab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Logistic Regression...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Tuning Random Forest...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Logistic Regression params: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "Best Random Forest params: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grids for GridSearch\n",
    "lr_param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l2', 'none'],\n",
    "    'classifier__solver': ['lbfgs', 'sag']\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Perform GridSearch for Logistic Regression\n",
    "print(\"Tuning Logistic Regression...\")\n",
    "lr_grid_search = GridSearchCV(\n",
    "    lr_pipeline, \n",
    "    lr_param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "lr_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Perform GridSearch for Random Forest\n",
    "print(\"Tuning Random Forest...\")\n",
    "rf_grid_search = GridSearchCV(\n",
    "    rf_pipeline, \n",
    "    rf_param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best models\n",
    "best_lr = lr_grid_search.best_estimator_\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best Logistic Regression params: {lr_grid_search.best_params_}\")\n",
    "print(f\"Best Random Forest params: {rf_grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "763a8384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance:\n",
      "==================================================\n",
      "Accuracy: 0.8055\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      1035\n",
      "           1       0.66      0.56      0.60       374\n",
      "\n",
      "    accuracy                           0.81      1409\n",
      "   macro avg       0.75      0.73      0.74      1409\n",
      "weighted avg       0.80      0.81      0.80      1409\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[926 109]\n",
      " [165 209]]\n",
      "\n",
      "Random Forest Performance:\n",
      "==================================================\n",
      "Accuracy: 0.8062\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87      1035\n",
      "           1       0.68      0.52      0.59       374\n",
      "\n",
      "    accuracy                           0.81      1409\n",
      "   macro avg       0.76      0.71      0.73      1409\n",
      "weighted avg       0.80      0.81      0.80      1409\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[943  92]\n",
      " [181 193]]\n",
      "\n",
      "Selected Random Forest as the best model\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Evaluate both models\n",
    "lr_accuracy = evaluate_model(best_lr, X_test, y_test, \"Logistic Regression\")\n",
    "rf_accuracy = evaluate_model(best_rf, X_test, y_test, \"Random Forest\")\n",
    "\n",
    "# Select the best model\n",
    "if lr_accuracy > rf_accuracy:\n",
    "    best_model = best_lr\n",
    "    print(\"\\nSelected Logistic Regression as the best model\")\n",
    "else:\n",
    "    best_model = best_rf\n",
    "    print(\"\\nSelected Random Forest as the best model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68db898c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline exported successfully as 'customer_churn_pipeline.joblib'\n",
      "Preprocessor exported successfully as 'churn_preprocessor.joblib'\n"
     ]
    }
   ],
   "source": [
    "# Export the best model pipeline\n",
    "joblib.dump(best_model, 'customer_churn_pipeline.joblib')\n",
    "print(\"Pipeline exported successfully as 'customer_churn_pipeline.joblib'\")\n",
    "\n",
    "# Also export the preprocessor separately for potential reuse\n",
    "joblib.dump(preprocessor, 'churn_preprocessor.joblib')\n",
    "print(\"Preprocessor exported successfully as 'churn_preprocessor.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca4ab869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction for sample customer:\n",
      "churn_prediction: No\n",
      "churn_probability: 0.26341281180570475\n",
      "confidence: High\n"
     ]
    }
   ],
   "source": [
    "# Example of how to use the exported pipeline in production\n",
    "def predict_churn(new_customer_data, pipeline_path='customer_churn_pipeline.joblib'):\n",
    "    \"\"\"\n",
    "    Predict churn for new customer data\n",
    "    \"\"\"\n",
    "    # Load the pipeline\n",
    "    pipeline = joblib.load(pipeline_path)\n",
    "    \n",
    "    # Ensure data is in DataFrame format with correct column names\n",
    "    if isinstance(new_customer_data, dict):\n",
    "        new_customer_data = pd.DataFrame([new_customer_data])\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = pipeline.predict(new_customer_data)\n",
    "    prediction_proba = pipeline.predict_proba(new_customer_data)\n",
    "    \n",
    "    # Return results\n",
    "    result = {\n",
    "        'churn_prediction': 'Yes' if prediction[0] == 1 else 'No',\n",
    "        'churn_probability': float(prediction_proba[0][1]),\n",
    "        'confidence': 'High' if max(prediction_proba[0]) > 0.7 else 'Medium'\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "sample_customer = {\n",
    "    'gender': 'Female',\n",
    "    'SeniorCitizen': 0,\n",
    "    'Partner': 'Yes',\n",
    "    'Dependents': 'No',\n",
    "    'tenure': 12,\n",
    "    'PhoneService': 'Yes',\n",
    "    'MultipleLines': 'No',\n",
    "    'InternetService': 'DSL',\n",
    "    'OnlineSecurity': 'No',\n",
    "    'OnlineBackup': 'Yes',\n",
    "    'DeviceProtection': 'No',\n",
    "    'TechSupport': 'No',\n",
    "    'StreamingTV': 'No',\n",
    "    'StreamingMovies': 'No',\n",
    "    'Contract': 'Month-to-month',\n",
    "    'PaperlessBilling': 'Yes',\n",
    "    'PaymentMethod': 'Electronic check',\n",
    "    'MonthlyCharges': 29.85,\n",
    "    'TotalCharges': 358.2\n",
    "}\n",
    "\n",
    "# Make prediction\n",
    "prediction_result = predict_churn(sample_customer)\n",
    "print(\"\\nPrediction for sample customer:\")\n",
    "for key, value in prediction_result.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba744c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive pipeline class for better reusability\n",
    "class ChurnPredictionPipeline:\n",
    "    def __init__(self, pipeline_path='customer_churn_pipeline.joblib'):\n",
    "        self.pipeline = joblib.load(pipeline_path)\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def predict(self, data):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        if isinstance(data, dict):\n",
    "            data = pd.DataFrame([data])\n",
    "        return self.pipeline.predict(data)\n",
    "    \n",
    "    def predict_proba(self, data):\n",
    "        \"\"\"Get prediction probabilities\"\"\"\n",
    "        if isinstance(data, dict):\n",
    "            data = pd.DataFrame([data])\n",
    "        return self.pipeline.predict_proba(data)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"Get feature importance if available\"\"\"\n",
    "        if hasattr(self.pipeline.named_steps['classifier'], 'feature_importances_'):\n",
    "            # For tree-based models\n",
    "            return self.pipeline.named_steps['classifier'].feature_importances_\n",
    "        elif hasattr(self.pipeline.named_steps['classifier'], 'coef_'):\n",
    "            # For linear models\n",
    "            return self.pipeline.named_steps['classifier'].coef_[0]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Usage example\n",
    "churn_predictor = ChurnPredictionPipeline()\n",
    "result = churn_predictor.predict(sample_customer)\n",
    "print(f\"Prediction: {result[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
